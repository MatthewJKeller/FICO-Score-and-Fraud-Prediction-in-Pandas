{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **SETUP:**"
      ],
      "metadata": {
        "id": "7lBbN9i_T9-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/archive\"\n",
        "\n",
        "transactions = pd.read_csv('/content/drive/My Drive/archive/50_transactions.csv')\n",
        "users = pd.read_csv('/content/drive/My Drive/archive/sd254_users.csv')\n",
        "data = pd.read_csv('/content/drive/My Drive/archive/sd254_users.csv')\n",
        "cards = pd.read_csv('/content/drive/My Drive/archive/temp_cards.csv')\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "sjs4ylGARUSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FICO SCORE PREDICTION:**"
      ],
      "metadata": {
        "id": "AKtsgoT9UEfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=[\"Person\", \"Birth Month\", \"Address\", \"Apartment\", \"City\", \"State\", \"Zipcode\", \"Per Capita Income - Zipcode\", \"Latitude\", \"Longitude\", \"Retirement Age\"], inplace=True)\n",
        "all_columns = data.columns.tolist()\n",
        "all_columns.remove('FICO Score')\n",
        "all_columns.remove('Num Credit Cards')\n",
        "data = data[all_columns + ['Num Credit Cards', 'FICO Score']]"
      ],
      "metadata": {
        "id": "wA_KjqkWRYfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data[\"Gender\"] = data[\"Gender\"].apply(lambda x: 0 if x == \"Male\" else 1)"
      ],
      "metadata": {
        "id": "PXcAGUMzRbKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data[\"Yearly Income - Person\"] = data[\"Yearly Income - Person\"].apply(lambda x: int(x[1:]))\n",
        "\n",
        "data[\"Total Debt\"] = data[\"Total Debt\"].apply(lambda x: int(x[1:]))\n"
      ],
      "metadata": {
        "id": "m2VZBDnCRbaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#data[\"FICO Score\"] = data[\"FICO Score\"].apply(lambda x: \"Very Low\" if x <630 else \"Low\" if x < 690 else \"Medium\" if x < 720 else \"Good\")\n",
        "data[\"FICO Score\"] = data[\"FICO Score\"].apply(lambda x: \"Very Low\" if x <650 else \"Good\")"
      ],
      "metadata": {
        "id": "yy2wjAoXRbkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data[\"FICO Score\"] = pd.qcut(data[\"FICO Score\"], q=4, labels=[\"Very Low\", \"Low\", \"Medium\", \"Good\"])\n",
        "data[\"FICO Score\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "gLsz9zeBRcI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n"
      ],
      "metadata": {
        "id": "sHEW3E8QRcWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = data.sample(frac = 0.8)\n",
        "test = data.drop(training.index)"
      ],
      "metadata": {
        "id": "fb3DUURXRciY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jtSzz8evRvc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training = training[training.columns[-4:]]\n",
        "test = test[test.columns[-4:]]"
      ],
      "metadata": {
        "id": "MvAe0XQrRwjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = training.set_index('FICO Score')\n",
        "test.set_index('FICO Score', inplace=True)"
      ],
      "metadata": {
        "id": "zpDHa5s6Rctm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.head()"
      ],
      "metadata": {
        "id": "95TqDrqMRc5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training2 = training#.apply(lambda x: (x-x.mean()) / x.std())"
      ],
      "metadata": {
        "id": "gOGy1fMhRdDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test2 = test#.apply(lambda x: (x-x.mean()) / x.std())"
      ],
      "metadata": {
        "id": "LCOgzXXiRdNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training2 = training2.apply(lambda x: x/magnitude(x), axis=1)\n",
        "test2     = test2.apply(lambda x: x/magnitude(x), axis=1)"
      ],
      "metadata": {
        "id": "3IO8G5O3RdZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = test2.dot(training2.T)"
      ],
      "metadata": {
        "id": "u7p1PoAoRd5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = similarities.idxmax(axis=1)\n",
        "sum(a == a.index) / len(a)"
      ],
      "metadata": {
        "id": "Twc9jl6cReEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def euclidean(x, y):\n",
        "    return np.linalg.norm(np.array(x[:-1]) - np.array(y[:-1]))\n",
        "\n",
        "def magnitude(a):\n",
        "    return np.linalg.norm(np.array(a[:-1]))\n",
        "\n",
        "def dot_product(a, b):\n",
        "    return np.dot(np.array(a[:-1]), np.array(b[:-1]))\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return dot_product(a, b) / (magnitude(a) * magnitude(b))\n",
        "\n",
        "similaritiesCos = test.apply(lambda x: training.apply(lambda y: cosine_similarity(x, y), axis=1), axis=1)\n",
        "\n",
        "\n",
        "similaritiesEuc = test.apply(lambda x: training.apply(lambda y: euclidean(x, y), axis=1), axis=1)\n",
        "\n",
        "similaritiesEuc.idxmin()"
      ],
      "metadata": {
        "id": "HT8yZRpYRecR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getCategory(row, similarities, similarity_type=\"euclidean\", k=25):\n",
        "   test_row_idx = row.name\n",
        "   similarity_row = similarities.loc[test_row_idx]\n",
        "   ascending = True if similarity_type == \"euclidean\" else False\n",
        "   sorted_similarities = similarity_row.sort_values(ascending=ascending)\n",
        "\n",
        "   nearest_indices = sorted_similarities.index[1:k+1]\n",
        "\n",
        "   fico_scores = []\n",
        "   for idx in nearest_indices:\n",
        "       if idx < len(training):\n",
        "           fico_score = training.loc[idx][\"FICO Score\"]\n",
        "           fico_scores.append(fico_score)\n",
        "\n",
        "   value_counts = pd.Series(fico_scores).value_counts()\n",
        "   return value_counts.idxmax()\n",
        "\n",
        "test[\"Predicted FICO Score Euclidean\"] = test.apply(lambda row: getCategory(row, similaritiesEuc, \"euclidean\"), axis=1)\n",
        "test[\"Predicted FICO Score Cosine\"] = test.apply(lambda row: getCategory(row, similaritiesCos, \"cosine\"), axis=1)"
      ],
      "metadata": {
        "id": "HO0ynYr9R-MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_euc = (test[\"FICO Score\"] == test[\"Predicted FICO Score Euclidean\"]).mean()\n",
        "accuracy_cos = (test[\"FICO Score\"] == test[\"Predicted FICO Score Cosine\"]).mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "lcQICjkZR-X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TruePositiveEuc = len(test[(test[\"FICO Score\"] == \"Good\") & (test[\"Predicted FICO Score Euclidean\"] == \"Good\")])\n",
        "FalsePositiveEuc = len(test[(test[\"FICO Score\"] != \"Good\") & (test[\"Predicted FICO Score Euclidean\"] == \"Good\")])\n",
        "FalseNegativeEuc = len(test[(test[\"FICO Score\"] == \"Good\") & (test[\"Predicted FICO Score Euclidean\"] != \"Good\")])\n",
        "TrueNegativeEuc = len(test[(test[\"FICO Score\"] != \"Good\") & (test[\"Predicted FICO Score Euclidean\"] != \"Good\")])\n",
        "\n",
        "f1ScoreEuc = 2 * (TruePositiveEuc / (2 * TruePositiveEuc + FalsePositiveEuc + FalseNegativeEuc))\n",
        "precisionEuc = TruePositiveEuc / (TruePositiveEuc + FalsePositiveEuc)\n",
        "recallEuc = TruePositiveEuc / (TruePositiveEuc + FalseNegativeEuc)\n",
        "\n",
        "print(\"Euclidean:\")\n",
        "print(f\"F1-Score: {f1ScoreEuc:.2%}\")\n",
        "print(f\"Precision: {precisionEuc:.2%}\")\n",
        "print(f\"Recall: {recallEuc:.2%}\")\n",
        "print(f\"Euclidean Accuracy: {accuracy_euc:.2%}\")\n",
        "\n",
        "TruePositiveCos = len(test[(test[\"FICO Score\"] == \"Good\") & (test[\"Predicted FICO Score Cosine\"] == \"Good\")])\n",
        "FalsePositiveCos = len(test[(test[\"FICO Score\"] != \"Good\") & (test[\"Predicted FICO Score Cosine\"] == \"Good\")])\n",
        "FalseNegativeCos = len(test[(test[\"FICO Score\"] == \"Good\") & (test[\"Predicted FICO Score Cosine\"] != \"Good\")])\n",
        "TrueNegativeCos = len(test[(test[\"FICO Score\"] != \"Good\") & (test[\"Predicted FICO Score Cosine\"] != \"Good\")])\n",
        "print(\"\\n\")\n",
        "f1ScoreCos = 2 * (TruePositiveCos / (2 * TruePositiveCos + FalsePositiveCos + FalseNegativeCos))\n",
        "precisionCos = TruePositiveCos / (TruePositiveCos + FalsePositiveCos)\n",
        "recallCos = TruePositiveCos / (TruePositiveCos + FalseNegativeCos)\n",
        "\n",
        "print(\"Cosine:\")\n",
        "print(f\"F1-Score: {f1ScoreCos:.2%}\")\n",
        "print(f\"Precision: {precisionCos:.2%}\")\n",
        "print(f\"Recall: {recallCos:.2%}\")\n",
        "print(f\"Cosine Accuracy: {accuracy_cos:.2%}\")\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "majorityResults = pd.DataFrame()\n",
        "majorityResults['actual'] = test['FICO Score']\n",
        "majorityResults['predicted'] = 'Good'\n",
        "majorityResults.head()\n",
        "\n",
        "TruePositiveMajority = len(majorityResults[(majorityResults['actual'] == 'Good') & (majorityResults['predicted'] == 'Good')])\n",
        "FalsePositiveMajority = len(majorityResults[(majorityResults['actual'] != 'Good') & (majorityResults['predicted'] == 'Good')])\n",
        "FalseNegativeMajority = len(majorityResults[(majorityResults['actual'] == 'Good') & (majorityResults['predicted'] != 'Good')])\n",
        "TrueNegativeMajority = len(majorityResults[(majorityResults['actual'] != 'Good') & (majorityResults['predicted'] != 'Good')])\n",
        "\n",
        "f1ScoreMajority = 2 * (TruePositiveMajority / (2 * TruePositiveMajority + FalsePositiveMajority + FalseNegativeMajority))\n",
        "precisionMajority = TruePositiveMajority / (TruePositiveMajority + FalsePositiveMajority)\n",
        "recallMajority = TruePositiveMajority / (TruePositiveMajority + FalseNegativeMajority)\n",
        "\n",
        "print(\"Majority Class Classifier:\")\n",
        "print(f\"F1-Score: {f1ScoreMajority:.2%}\")\n",
        "print(f\"Precision: {precisionMajority:.2%}\")\n",
        "print(f\"Recall: {recallMajority:.2%}\")\n",
        "majorityClassAccuracy = len(test[(test[\"FICO Score\"] == \"Good\")]) / len(test)\n",
        "print(f\"Majority Class Accuracy: {majorityClassAccuracy:.2%}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "randomResults = pd.DataFrame()\n",
        "randomResults['actual'] = test['FICO Score']\n",
        "randomResults['predicted'] = np.random.choice(['Very Low', 'Low', 'Medium', 'Good'], size=len(test))\n",
        "randomResults.head()\n",
        "\n",
        "TruePositiveRandom = len(randomResults[(randomResults['actual'] == 'Good') & (randomResults['predicted'] == 'Good')])\n",
        "FalsePositiveRandom = len(randomResults[(randomResults['actual'] != 'Good') & (randomResults['predicted'] == 'Good')])\n",
        "FalseNegativeRandom = len(randomResults[(randomResults['actual'] == 'Good') & (randomResults['predicted'] != 'Good')])\n",
        "TrueNegativeRandom = len(randomResults[(randomResults['actual'] != 'Good') & (randomResults['predicted'] != 'Good')])\n",
        "\n",
        "f1ScoreRandom = 2 * (TruePositiveRandom / (2 * TruePositiveRandom + FalsePositiveRandom + FalseNegativeRandom))\n",
        "precisionRandom = TruePositiveRandom / (TruePositiveRandom + FalsePositiveRandom)\n",
        "recallRandom = TruePositiveRandom / (TruePositiveRandom + FalseNegativeRandom)\n",
        "\n",
        "print(\"Random Classifier:\")\n",
        "print(f\"F1-Score: {f1ScoreRandom:.2%}\")\n",
        "print(f\"Precision: {precisionRandom:.2%}\")\n",
        "print(f\"Recall: {recallRandom:.2%}\")\n",
        "randomClassAccuracy = len(test[(test[\"FICO Score\"] == \"Good\")]) / len(test)\n",
        "print(f\"Random Class Accuracy: {randomClassAccuracy:.2%}\")"
      ],
      "metadata": {
        "id": "TqsFp8tOR-wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head(5)"
      ],
      "metadata": {
        "id": "XCnXW_9FR-1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_predict(training, test):\n",
        "    features = training.iloc[:, :-3]\n",
        "    priors = training['FICO Score'].value_counts(normalize=True)\n",
        "    likelihoods = pd.DataFrame(index=features.columns, columns=priors.index)\n",
        "\n",
        "    for score in priors.index:\n",
        "        score_data = training[training['FICO Score'] == score]\n",
        "        for feature in features.columns:\n",
        "            feature_values = pd.to_numeric(score_data[feature], errors='coerce')\n",
        "            likelihoods.loc[feature, score] = (len(feature_values[feature_values > 0]) + 1) / (len(score_data) + 2)\n",
        "\n",
        "    predictions = []\n",
        "    for _, row in test.iterrows():\n",
        "        scores = {category: np.log(prior) for category, prior in priors.items()}\n",
        "        for feature in features.columns:\n",
        "            feature_value = pd.to_numeric(row[feature], errors='coerce')\n",
        "            if pd.notna(feature_value) and feature_value > 0:\n",
        "                for category in scores:\n",
        "                    scores[category] += np.log(likelihoods.loc[feature, category])\n",
        "        predictions.append(max(scores.items(), key=lambda x: x[1])[0])\n",
        "    return predictions\n",
        "\n",
        "test['Predicted FICO Score NB'] = naive_bayes_predict(training, test)\n",
        "\n",
        "TruePositiveNB = len(test[(test[\"FICO Score\"] == \"Good\") & (test[\"Predicted FICO Score NB\"] == \"Good\")])\n",
        "FalsePositiveNB = len(test[(test[\"FICO Score\"] != \"Good\") & (test[\"Predicted FICO Score NB\"] == \"Good\")])\n",
        "FalseNegativeNB = len(test[(test[\"FICO Score\"] == \"Good\") & (test[\"Predicted FICO Score NB\"] != \"Good\")])\n",
        "TrueNegativeNB = len(test[(test[\"FICO Score\"] != \"Good\") & (test[\"Predicted FICO Score NB\"] != \"Good\")])\n",
        "\n",
        "f1ScoreNB = 2 * (TruePositiveNB / (2 * TruePositiveNB + FalsePositiveNB + FalseNegativeNB))\n",
        "precisionNB = TruePositiveNB / (TruePositiveNB + FalsePositiveNB)\n",
        "recallNB = TruePositiveNB / (TruePositiveNB + FalseNegativeNB)\n",
        "accuracy_nb = len(test[(test[\"FICO Score\"] == \"Good\")]) / len(test)\n",
        "\n",
        "print(\"Naive Bayes:\")\n",
        "print(f\"F1-Score: {f1ScoreNB:.2%}\")\n",
        "print(f\"Precision: {precisionNB:.2%}\")\n",
        "print(f\"Recall: {recallNB:.2%}\")\n",
        "print(f\"Naive Bayes Accuracy: {accuracy_nb:.2%}\")"
      ],
      "metadata": {
        "id": "EwnLn3ObSFOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FRAUD DETECTION:**"
      ],
      "metadata": {
        "id": "CjEgjOQESHN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions['Amount'] = transactions['Amount'].apply(lambda x: float(x[1:]))\n"
      ],
      "metadata": {
        "id": "PHkh0SSeSM0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_zip(row):\n",
        "  if not pd.isna(row['Zip']):\n",
        "    return row['Zip']\n",
        "  elif row['Merchant City'] == 'ONLINE':\n",
        "      return 0\n",
        "  else:\n",
        "    return -1"
      ],
      "metadata": {
        "id": "MNBTlSb8SNPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions['Zip'] = transactions.apply(lambda x: modify_zip(x), axis = 1)\n"
      ],
      "metadata": {
        "id": "DYCXfGNiSNkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_transactions = transactions.drop(columns = ['Merchant City', 'Use Chip', 'Time', 'Month', 'Year', 'MCC', 'Day', 'Time', 'Year', 'Month', 'Errors?'])\n",
        "x = pd.get_dummies(transactions['Use Chip'])\n",
        "\n",
        "transactions['Time'] = transactions['Time'].apply(lambda x: 'time_' + x.split(':')[0])\n",
        "x2 = pd.get_dummies(transactions['Time'])\n",
        "\n",
        "bins = [1990, 1994, 1999, 2004, 2009, 2014, 2020]\n",
        "labels = ['1990+', '1995+', '2000+', '2005+', '2010+', '2015+']\n",
        "transactions['Year Cat'] = pd.cut(transactions['Year'], bins = bins, labels = labels)\n",
        "x3 = pd.get_dummies(transactions['Year Cat'])\n",
        "\n",
        "bins = [0, 10, 20, 32]\n",
        "labels = ['early_month',  'mid_month', 'end_month']\n",
        "transactions['days Cat'] = pd.cut(transactions['Day'], bins = bins, labels = labels)\n",
        "x4 = pd.get_dummies(transactions['days Cat'])\n",
        "\n",
        "bins = [0, 3, 6, 9, 13]\n",
        "labels = ['Quarter 1',  'Quarter 2', 'Quarter 3', 'Quarter 4']\n",
        "transactions['Month Cat'] = pd.cut(transactions['Month'], bins = bins, labels = labels)\n",
        "x5 = pd.get_dummies(transactions['Month Cat'])\n",
        "\n",
        "x6 = pd.get_dummies(transactions['Errors?'])\n",
        "\n",
        "binary_transactions = pd.concat([binary_transactions, x, x2, x3, x4, x5, x6], axis = 1)"
      ],
      "metadata": {
        "id": "ZLMCVN5fSPLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_transactions.drop(columns = ['Merchant State'], inplace = True)"
      ],
      "metadata": {
        "id": "4wu7R28JSPIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_transactions['Is Fraud?'].replace({'Yes': 1, 'No': 0})"
      ],
      "metadata": {
        "id": "dapQjVp2SPHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train = binary_transactions.sample(frac = .8)\n",
        "\n",
        "test = binary_transactions.drop(train.index)\n",
        "\n",
        "X_train = train.apply(lambda x: pd.Series(x), axis = 1)\n",
        "X_test  = test.apply(lambda x: pd.Series(x), axis = 1)\n",
        "y_train = train['Is Fraud?']\n",
        "y_test = test['Is Fraud?']"
      ],
      "metadata": {
        "id": "1_UWP5c0SPF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "tree.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "YknH8-wDSPEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in binary_transactions.columns:\n",
        "  if len(binary_transactions[binary_transactions[c].isna()]) != 0:\n",
        "    print(c)"
      ],
      "metadata": {
        "id": "Fqu6DkdjSPC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cards = cards.drop(columns = ['Card Number',\t'Expires',\t'CVV', 'Card Brand', 'Card Type'])\n",
        "\n",
        "x = pd.get_dummies(cards[['Card Brand', 'Card Type']])\n",
        "\n",
        "binary_cards['Has Chip'].replace({'YES': 1, 'NO': 0}, inplace = True)\n",
        "binary_cards['Credit Limit'] = binary_cards['Credit Limit'].apply(lambda x: float(x[1:]))\n",
        "binary_cards['Acct Open Date'] = binary_cards['Acct Open Date'].apply(lambda x: \"\".join(x.split('/')[::-1]))\n",
        "binary_cards['Card on Dark Web'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
        "binary_cards = pd.concat([binary_cards, x], axis = 1)\n",
        "binary_cards['Acct Open Date'] = cards['Acct Open Date'].apply(lambda x: int(\"\".join(x.split('/')[::-1])))"
      ],
      "metadata": {
        "id": "cip96OfvSPBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cards.loc[binary_cards['std_legit_spending'].isna(), 'std_legit_spending'] = 1 # it is only for two of them, which are not in the transactions subset so I think it is fine"
      ],
      "metadata": {
        "id": "Pc9TXcFQSPAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in binary_cards.columns:\n",
        "  if len(binary_cards[binary_cards[c].isna()]) != 0:\n",
        "    print(c)"
      ],
      "metadata": {
        "id": "AWssaDZcSO75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions[(transactions['User'] == 255) & (transactions['Card']) == 3]"
      ],
      "metadata": {
        "id": "JHfyMKV3SO2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users['User'] = users.index\n",
        "users['Gender'].replace({'Female': 1, 'Male': 0}, inplace = True)\n",
        "bins = [1917, 1929, 1939, 1949, 1959, 1969, 1979, 1989, 2003]\n",
        "labels = ['birth_year_1918+', 'birth_year_1930s', 'birth_year_1940s', 'birth_year_1950s', 'birth_year_1960s', 'birth_year_1970s', \\\n",
        "          'birth_year_1980s', 'birth_year_1990+']\n",
        "users['birth_year Cat'] = pd.cut(users['Birth Year'], bins=bins, labels=labels)\n",
        "x = pd.get_dummies(users['birth_year Cat'])\n",
        "\n",
        "\n",
        "labels = ['early retirement', 'below average retirement', 'above average retirement', 'late retirment']\n",
        "users['retirement Cat'] = pd.qcut(users['Retirement Age'], q = 4, labels = labels)\n",
        "x4 = pd.get_dummies(users['retirement Cat'])\n",
        "\n",
        "bins = [0, 629, 689, 719, 851]\n",
        "labels = ['Very Low FICO',  'Low FICO', 'Medium FICO', 'Good FICO']\n",
        "users['FICO Cat'] = pd.cut(users['FICO Score'], bins = bins, labels = labels)\n",
        "x5 = pd.get_dummies(users['FICO Cat'])\n",
        "\n",
        "binary_users = users.drop(columns = ['FICO Score', 'Retirement Age', 'Birth Year', 'Address', 'Apartment', 'City', 'Birth Month', 'Current Age', \\\n",
        "                                     'Latitude', 'Longitude', 'FICO Cat', 'retirement Cat', 'birth_year Cat', 'Person'])\n",
        "binary_users = pd.concat([binary_users, x, x4, x5], axis = 1)"
      ],
      "metadata": {
        "id": "wY7nOOPASOqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_users['Per Capita Income - Zipcode'] = binary_users['Per Capita Income - Zipcode'].apply(lambda x: float(x[1:]))\n",
        "binary_users['Yearly Income - Person'] = binary_users['Yearly Income - Person'].apply(lambda x: float(x[1:]))\n",
        "binary_users['Total Debt'] = binary_users['Total Debt'].apply(lambda x: float(x[1:]))"
      ],
      "metadata": {
        "id": "m6ri-XR2SOnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in binary_users.columns:\n",
        "  if len(binary_users[binary_users[c].isna()]) != 0:\n",
        "    print(c)"
      ],
      "metadata": {
        "id": "OSZNVro8SOlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(binary_users[binary_users['Gender'].isna()])"
      ],
      "metadata": {
        "id": "MngGcDwmSOjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge = pd.merge(binary_transactions, binary_cards, on=['User', 'Card'], how='left', suffixes=('_transactions', '_cards'))\n",
        "merge = pd.merge(merge, binary_users, on=['User'], how='left', suffixes=('_merged', '_users'))\n",
        "merge['Is Fraud?'].replace({'Yes': 1, 'No': 0}, inplace = True)\n",
        "merge['in_state'] = merge.apply(lambda x: x['Merchant State'] == x['State'], axis = 1)\n",
        "merge.drop(columns = ['Merchant State', 'State'], inplace = True)\n",
        "cols = [c for c in merge.columns if c != 'Is Fraud?'] + ['Is Fraud?']\n",
        "merge = merge[cols]"
      ],
      "metadata": {
        "id": "JobakqKRSOf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in merge.columns:\n",
        "    # Check if the column data type is not one of the specified types\n",
        "    if not (np.issubdtype(merge[c].dtype, np.number) or merge[c].dtype == bool):\n",
        "        print(f'is not a number {c}')\n",
        "    if len(merge[merge[c].isna()]) != 0:\n",
        "      print(f'is na {c}')"
      ],
      "metadata": {
        "id": "bDEG5DbMSORV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge.info()"
      ],
      "metadata": {
        "id": "ZxpgaiqQS43e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = pd.read_csv('/content/drive/My Drive/archive/cosine_holy_grail.csv')\n",
        "transactions.drop(columns = ['Unnamed: 0'], inplace = True)\n",
        "merge = transactions"
      ],
      "metadata": {
        "id": "KeQfx95HS40U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge"
      ],
      "metadata": {
        "id": "eT2NvR__S4u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge.drop(columns = [\"in_US\", 'in_state', 'is_suspicious_amount'], inplace = True)"
      ],
      "metadata": {
        "id": "_ouAyQlIS4s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge"
      ],
      "metadata": {
        "id": "wE2SZa6NS4qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def true_positive(df, positive):\n",
        "  return len(df[(df['x'] == positive) & (df['y'] == positive)])\n",
        "\n",
        "def true_negative(df, positive):\n",
        "  return len(df[(df['x'] == (1-positive)) & df['y'] == (1-positive)])\n",
        "\n",
        "def false_positive(df, positive):\n",
        "  return len(df[(df['x'] == positive) & (df['y'] == (1 - positive))])\n",
        "\n",
        "def false_negative(df, positive):\n",
        "  return len(df[(df['x'] == (1 - positive)) & df['y'] == positive])\n",
        "\n",
        "def get_precision(df, positive):\n",
        "  denominator = (true_positive(df, positive) + false_positive(df, positive))\n",
        "  if denominator == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return true_positive(df, positive)/denominator\n",
        "\n",
        "def get_recall(df, positive):\n",
        "  denominator = (true_positive(df, positive) + false_negative(df, positive))\n",
        "  if denominator == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return true_positive(df, positive)/denominator\n",
        "\n",
        "def get_f1(df, positive):\n",
        "  denominator = (get_precision(df, positive) + get_recall(df, positive))\n",
        "  if denominator == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 2 * ((get_precision(df, positive) * get_recall(df, positive))/ denominator)\n",
        "\n",
        "def get_accuracy(df, positive):\n",
        "  denominator = (true_positive(df, positive) + false_positive(df, positive) + false_negative(df, positive) + true_negative(df, positive))\n",
        "  if denominator == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return (true_positive(df, positive) + true_negative(df, positive))/denominator\n"
      ],
      "metadata": {
        "id": "nkam14ygS4nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge.corr()['Is Fraud?'][merge.corr()['Is Fraud?'].abs().apply(lambda x: x>.10)].abs().sort_values(ascending = False)\n",
        "merge.corr()['Is Fraud?'][merge.corr()['Is Fraud?'].abs().apply(lambda x: x>.10)].abs().sort_values(ascending = False).index"
      ],
      "metadata": {
        "id": "u-p06vkaS4iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = merge[['in_US', 'in_state', 'Zip', 'Online Transaction',\n",
        "       'Swipe Transaction', 'is_suspicious_amount', 'Amount',\n",
        "       'Num Credit Cards', 'Is Fraud?']]"
      ],
      "metadata": {
        "id": "1K0asKcWS4gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def magnitude(a):\n",
        "    return np.linalg.norm(np.array(a[:-1]))"
      ],
      "metadata": {
        "id": "F90WRcwhS4es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = transactions.sample(frac = .8)\n",
        "\n",
        "test = transactions.drop(train.index)\n",
        "\n",
        "X_train = train.apply(lambda x: pd.Series(x), axis = 1)\n",
        "X_test  = test.apply(lambda x: pd.Series(x), axis = 1)\n",
        "X_train.index = train['Is Fraud?']\n",
        "y_train = train['Is Fraud?']\n",
        "y_test = test['Is Fraud?']"
      ],
      "metadata": {
        "id": "JXoN63pQS4dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.apply(lambda x: x/magnitude(x))\n",
        "X_test  = X_test.apply(lambda x: x/magnitude(x))\n",
        "X_train.index = train['Is Fraud?']\n",
        "cosine_sim = X_test.dot(X_train.T)\n",
        "x = cosine_sim.apply(lambda row: pd.Series(row.sort_values(ascending=False).head(101).index.tolist()), axis=1)"
      ],
      "metadata": {
        "id": "nyhwnpqHTKz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "evrnYhh7S4bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_variable = []\n",
        "\n",
        "measure = []\n",
        "\n",
        "support = []\n",
        "\n",
        "accuracy = []\n",
        "\n",
        "precision = []\n",
        "\n",
        "recall = []\n",
        "\n",
        "f1 = []\n",
        "\n",
        "for k in [1, 5, 11, 25, 51, 75, 101]:\n",
        "  temp = x.apply(lambda row: row.head(k).mode(), axis = 1)\n",
        "  y = y_test.to_frame()\n",
        "  merge_cosine = temp.join(y)\n",
        "  merge_cosine.rename(columns = {0: 'x', 'Is Fraud?': 'y'}, inplace = True)\n",
        "  l = [(0, merge_cosine), (1, merge_cosine)]\n",
        "  for target, df in l:\n",
        "    measure.append(k)\n",
        "    target_variable.append(target)\n",
        "    support.append(len(transactions[transactions['Is Fraud?'] == target]))\n",
        "    accuracy.append(get_accuracy(df, target))\n",
        "    precision.append(get_precision(df, target))\n",
        "    recall.append(get_recall(df, target))\n",
        "    f1.append(get_f1(df, target))\n",
        "\n",
        "result = pd.DataFrame({'Target Variable': target_variable, 'Measure/Model': measure, 'Support': support, 'Acccuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1})"
      ],
      "metadata": {
        "id": "72hxbwV_S4ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "kKFpyzH3S4UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.groupby('Measure/Model').mean()"
      ],
      "metadata": {
        "id": "P7JWZ2GlS4SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = {}\n",
        "for name, group in train.groupby(['Is Fraud?']):\n",
        "  l[name[0]] = ((1+group.sum())/(len(train.columns) + group.sum().sum()))\n",
        "\n",
        "transactions_sentiment = pd.concat([l[1], l[0]], axis = 1)\n",
        "transactions_sentiment['sentiment'] = transactions_sentiment.apply(lambda x: x.idxmax(), axis = 1)"
      ],
      "metadata": {
        "id": "4gwcdYxES4P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l[0]"
      ],
      "metadata": {
        "id": "V_sllCgxS4NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentiment = pd.DataFrame()\n",
        "def get_sentiment(row, sent):\n",
        "  row = pd.Series(row[row >= 1].index)\n",
        "\n",
        "  x = pd.Series(row.apply(lambda x: np.log(transactions_sentiment.loc[x, sent])))\n",
        "\n",
        "  return np.log(train['Is Fraud?'].value_counts(normalize = True).loc[sent]) + x.sum()\n",
        "\n",
        "test_sentiment['Legit'] = test.iloc[:, :-1].apply(lambda row: get_sentiment(row, 0), axis = 1)\n",
        "\n",
        "test_sentiment['Fraud'] = test.iloc[:, :-1].apply(lambda row: get_sentiment(row, 1), axis = 1)\n",
        "\n",
        "y_pred = pd.Series(test_sentiment.apply(lambda x: x.idxmax(), axis = 1))\n",
        "\n",
        "x = y_pred.to_frame()\n",
        "y = test['Is Fraud?'].to_frame()\n",
        "bayes = x.join(y)\n",
        "bayes.rename(columns = {0: 'x', 'Is Fraud?': 'y'}, inplace = True)\n",
        "bayes.replace({'Fraud': 1, 'Legit': 0}, inplace = True)"
      ],
      "metadata": {
        "id": "ez46UnNeTS00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bayes['x'].unique()"
      ],
      "metadata": {
        "id": "nFHIGEa8TSxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_df = x.copy()\n",
        "random_df[0] = random_df[0].apply(lambda _: random.randint(0,1))\n",
        "random_df = random_df.join(y)\n",
        "random_df.rename(columns = {0:'x', 'Is Fraud?':'y'}, inplace = True)"
      ],
      "metadata": {
        "id": "5CUM10XDTSuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "majority_df = x.copy()\n",
        "majority_df[0] = majority_df[0].apply(lambda _: 0)\n",
        "majority_df = majority_df.join(y)\n",
        "majority_df.rename(columns = {0:'x', 'Is Fraud?':'y'}, inplace = True)"
      ],
      "metadata": {
        "id": "uzP8W39OTSqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = [(0, euclidean_dist), (1, euclidean_dist)]\n",
        "\n",
        "target_variable = []\n",
        "\n",
        "measure = ['bayes', 'bayes', 'cosine', 'cosine', 'majority', 'majority', 'random', 'random']\n",
        "\n",
        "support = []\n",
        "\n",
        "accuracy = []\n",
        "\n",
        "precision = []\n",
        "\n",
        "recall = []\n",
        "\n",
        "f1 = []\n",
        "\n",
        "for target, df in l:\n",
        "  target_variable.append(target)\n",
        "  support.append(len(transactions[transactions['Is Fraud?'] == target]))\n",
        "  accuracy.append(get_accuracy(df, target))\n",
        "  precision.append(get_precision(df, target))\n",
        "  recall.append(get_recall(df, target))\n",
        "  f1.append(get_f1(df, target))\n",
        "\n",
        "result = pd.DataFrame({'Target Variable': target_variable, 'Measure/Model': measure, 'Support': support, 'Acccuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1})"
      ],
      "metadata": {
        "id": "lQhyQZjJTSnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.groupby('Measure/Model').mean()"
      ],
      "metadata": {
        "id": "Y4pPGL82TSj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "4OtMq4VOTSgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = transactions.sample(frac = .8)\n",
        "\n",
        "test = transactions.drop(train.index)\n",
        "\n",
        "X_train = train.apply(lambda x: pd.Series(x), axis = 1)\n",
        "X_test  = test.apply(lambda x: pd.Series(x), axis = 1)\n",
        "X_train.index = train['Is Fraud?']\n",
        "y_train = train['Is Fraud?']\n",
        "y_test = test['Is Fraud?']"
      ],
      "metadata": {
        "id": "rUUtOCm_TScn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_variable = []\n",
        "\n",
        "measure = []\n",
        "\n",
        "support = []\n",
        "\n",
        "accuracy = []\n",
        "\n",
        "precision = []\n",
        "\n",
        "recall = []\n",
        "\n",
        "f1 = []\n",
        "\n",
        "\n",
        "for k in [1, 3, 5]:\n",
        "  temp = pd.DataFrame(euc_x.apply(lambda row: row.head(k).mode().iloc[0], axis = 1))\n",
        "  y = y_test.to_frame()\n",
        "  merge_euclidean = temp.join(y)\n",
        "  merge_euclidean.rename(columns = {0: 'x', 'FICO Score': 'y'}, inplace = True)\n",
        "  l = [(0, merge_euclidean), (1, merge_euclidean)]\n",
        "\n",
        "  for target, df in l:\n",
        "    measure.append(k)\n",
        "    target_variable.append(target)\n",
        "    support.append(len(data[data['FICO Score'] == target]))\n",
        "    accuracy.append(get_accuracy(df, target))\n",
        "    precision.append(get_precision(df, target))\n",
        "    recall.append(get_recall(df, target))\n",
        "    f1.append(get_f1(df, target))\n",
        "\n",
        "result = pd.DataFrame({'Target Variable': target_variable, 'Measure/Model': measure, 'Support': support, 'Acccuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1})"
      ],
      "metadata": {
        "id": "gkfMsW9MTSXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions.info()\n",
        "\n"
      ],
      "metadata": {
        "id": "RQVCKPKJTSS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = test.sample(n = 500)"
      ],
      "metadata": {
        "id": "Wwj66uYjTSPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = test.iloc[:, -1]\n",
        "test = test.iloc[:, :-1]"
      ],
      "metadata": {
        "id": "wTHeMSjVTSNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.iloc[:, 2:-1]"
      ],
      "metadata": {
        "id": "Qdp2b1lkTSLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "zH5-ow8STSGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.index = y_train"
      ],
      "metadata": {
        "id": "85TgmY4uTSEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_it(transaction, k):\n",
        "\n",
        "    #convert transaciton to numpy array\n",
        "    transaction = transaction.to_numpy()\n",
        "\n",
        "    #compute difference\n",
        "    differences = train.to_numpy() - transaction\n",
        "\n",
        "    distances = np.sum(differences**2, axis=1)\n",
        "\n",
        "    top_indices = np.argsort(distances)[:k]\n",
        "\n",
        "    #Use labels to get is fraud label\n",
        "    top_labels = train.iloc[top_indices, -1]\n",
        "\n",
        "    return pd.Series(top_labels.index).mode()\n",
        "\n",
        "euclidean_dist = test.apply(lambda x: train_it(x, k=5), axis=1)"
      ],
      "metadata": {
        "id": "gGmvdJ2tTvr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_variable = []\n",
        "\n",
        "measure = []\n",
        "\n",
        "support = []\n",
        "\n",
        "accuracy = []\n",
        "\n",
        "precision = []\n",
        "\n",
        "recall = []\n",
        "\n",
        "f1 = []\n",
        "temp_euc = euclidean_dist.apply(lambda x: x.apply(lambda col: y_train.loc[col]), axis = 1)\n",
        "\n",
        "for k in [1, 3, 5]:\n",
        "  temp = pd.DataFrame(temp_euc.apply(lambda x: x.head(k).mode().iloc[0], axis = 1))\n",
        "  y = y_test.to_frame()\n",
        "  merge_cosine = temp.join(y)\n",
        "  merge_cosine.rename(columns = {0: 'x', 'Is Fraud?': 'y'}, inplace = True)\n",
        "  l = [(0, merge_cosine), (1, merge_cosine)]\n",
        "\n",
        "  for target, df in l:\n",
        "    measure.append(k)\n",
        "    target_variable.append(target)\n",
        "    # support.append(len(transactions[transactions['Is Fraud?'] == target]))\n",
        "    accuracy.append(get_accuracy(df, target))\n",
        "    precision.append(get_precision(df, target))\n",
        "    recall.append(get_recall(df, target))\n",
        "    f1.append(get_f1(df, target))\n",
        "\n",
        "result = pd.DataFrame({'Target Variable': target_variable, 'Measure/Model': measure, 'Acccuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1})"
      ],
      "metadata": {
        "id": "2ToyVR4rTSCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "IR0RIgkGT1XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge_cosine['y'].unique()\n",
        "y_test.unique()"
      ],
      "metadata": {
        "id": "1StBqL8qT2lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.groupby('Measure/Model').mean()"
      ],
      "metadata": {
        "id": "MY1_2Pv1T3-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_eucy = y_test.to_frame()\n",
        "  merge_cosine = temp.join(y)\n",
        "  merge_cosine.rename(columns = {0: 'x', 'Is Fraud?': 'y'}, inplace = True)\n",
        "  l = [(0, merge_cosine), (1, merge_cosine)]\n",
        "\n",
        "  for target, df in l:\n",
        "    measure.append(k)\n",
        "    target_variable.append(target)\n",
        "    support.append(len(transactions[transactions['Is Fraud?'] == target]))\n",
        "    accuracy.append(get_accuracy(df, target))\n",
        "    precision.append(get_precision(df, target))\n",
        "    recall.append(get_recall(df, target))\n",
        "    f1.append(get_f1(df, target))\n",
        "\n",
        "result = pd.DataFrame({'Target Variable': target_variable, 'Measure/Model': measure, 'Support': support, 'Acccuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1})"
      ],
      "metadata": {
        "id": "F3IzJthkT473"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}